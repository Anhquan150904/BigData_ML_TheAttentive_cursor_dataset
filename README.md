üìò H∆∞·ªõng D·∫´n Thi·∫øt L·∫≠p M√¥i Tr∆∞·ªùng Ph√¢n T√≠ch D·ªØ Li·ªáu (Spark & Cassandra)
T√†i li·ªáu n√†y h∆∞·ªõng d·∫´n chi ti·∫øt c√°ch c√†i ƒë·∫∑t m√¥i tr∆∞·ªùng ƒë·ªÉ ch·∫°y d·ª± √°n ph√¢n t√≠ch h√†nh vi ng∆∞·ªùi d√πng (Attentive Cursor Dataset) s·ª≠ d·ª•ng PySpark, Cassandra (Docker) v√† Python 3.10 tr√™n Windows.

üìã M·ª•c l·ª•c
Y√™u c·∫ßu h·ªá th·ªëng & T·∫£i ph·∫ßn m·ªÅm

C√†i ƒë·∫∑t & C·∫•u h√¨nh Bi·∫øn m√¥i tr∆∞·ªùng (Quan tr·ªçng)

C√†i ƒë·∫∑t Database Cassandra (Docker)

Thi·∫øt l·∫≠p M√¥i tr∆∞·ªùng Python

D·ªØ li·ªáu d·ª± √°n

1. Y√™u c·∫ßu h·ªá th·ªëng & T·∫£i ph·∫ßn m·ªÅm
Vui l√≤ng t·∫£i xu·ªëng c√°c th√†nh ph·∫ßn sau (ch∆∞a c·∫ßn c√†i ƒë·∫∑t ngay, ch·ªâ c·∫ßn t·∫£i v·ªÅ):

A. Java Development Kit (JDK)
Spark y√™u c·∫ßu Java ƒë·ªÉ ch·∫°y.

Phi√™n b·∫£n: Java 11 (LTS)

Link t·∫£i: Adoptium Temurin OpenJDK 11

L∆∞u √Ω: Ch·ªçn file c√†i ƒë·∫∑t .msi cho Windows (x64).

B. Apache Spark
Phi√™n b·∫£n: 3.5.1 (Pre-built for Hadoop 3.3)

Link t·∫£i: Huawei Cloud Repo - spark-3.5.1-bin-hadoop3.tgz

L∆∞u √Ω: File n√†y t·∫£i v·ªÅ c·∫ßn gi·∫£i n√©n, kh√¥ng c·∫ßn ch·∫°y c√†i ƒë·∫∑t.

C. Hadoop Winutils (Cho Windows)
Windows c·∫ßn file n√†y ƒë·ªÉ gi·∫£ l·∫≠p m√¥i tr∆∞·ªùng Hadoop.

Phi√™n b·∫£n: Hadoop 3.3.6

Link t·∫£i: Winutils GitHub (winutils.exe)

C·∫ßn t·∫£i th√™m: hadoop.dll (c√πng th∆∞ m·ª•c trong link tr√™n n·∫øu c√≥, ho·∫∑c t√¨m trong repo ƒë√≥).

D. Python
Phi√™n b·∫£n: 3.10.x

Link t·∫£i: Python 3.10.11 Download

2. C√†i ƒë·∫∑t & C·∫•u h√¨nh Bi·∫øn m√¥i tr∆∞·ªùng (Quan tr·ªçng)
ƒê√¢y l√† b∆∞·ªõc quan tr·ªçng nh·∫•t, n·∫øu l√†m sai Spark s·∫Ω kh√¥ng ch·∫°y.

B∆∞·ªõc 2.1: C√†i ƒë·∫∑t Java
Ch·∫°y file c√†i ƒë·∫∑t JDK 11 ƒë√£ t·∫£i.

Ghi nh·ªõ ƒë∆∞·ªùng d·∫´n c√†i ƒë·∫∑t (V√≠ d·ª•: C:\Program Files\Eclipse Adoptium\jdk-11.0.18.10-hotspot).

B∆∞·ªõc 2.2: Gi·∫£i n√©n Spark
Gi·∫£i n√©n file spark-3.5.1-bin-hadoop3.tgz (d√πng WinRAR ho·∫∑c 7-Zip).

Di chuy·ªÉn th∆∞ m·ª•c ƒë√£ gi·∫£i n√©n ra ·ªï ƒëƒ©a g·ªëc ƒë·ªÉ t√™n ng·∫Øn g·ªçn.

V√≠ d·ª•: D:\Spark\spark-3.5.1-bin-hadoop3

B∆∞·ªõc 2.3: C√†i ƒë·∫∑t Winutils (Hadoop Home)
T·∫°o th∆∞ m·ª•c: D:\Hadoop

Trong th∆∞ m·ª•c ƒë√≥, t·∫°o ti·∫øp th∆∞ m·ª•c bin -> D:\Hadoop\bin

Copy file winutils.exe (v√† hadoop.dll n·∫øu c√≥) v√†o th∆∞ m·ª•c D:\Hadoop\bin.

B∆∞·ªõc 2.4: C·∫•u h√¨nh Environment Variables
M·ªü Edit the system environment variables tr√™n Windows -> B·∫•m Environment Variables.

T·∫°o c√°c bi·∫øn m·ªõi (System Variables - Ph·∫ßn b√™n d∆∞·ªõi):

JAVA_HOME: C:\Program Files\Eclipse Adoptium\jdk-11... (ƒë∆∞·ªùng d·∫´n c√†i Java).

HADOOP_HOME: D:\Hadoop (Th∆∞ m·ª•c ch·ª©a folder bin).

SPARK_HOME: D:\Spark\spark-3.5.1-bin-hadoop3

C·∫≠p nh·∫≠t bi·∫øn PATH:

T√¨m bi·∫øn Path trong System Variables -> B·∫•m Edit.

Th√™m m·ªõi (New) c√°c d√≤ng sau:

%JAVA_HOME%\bin

%HADOOP_HOME%\bin

%SPARK_HOME%\bin

3. C√†i ƒë·∫∑t Database Cassandra (Docker)
S·ª≠ d·ª•ng Docker ƒë·ªÉ ch·∫°y Cassandra server nhanh ch√≥ng.

M·ªü CMD ho·∫∑c PowerShell.


Bash

docker pull cassandra:4.1
Ch·∫°y Container:

Bash

docker run --name cass-node -d -p 9042:9042 cassandra:4.1
Ki·ªÉm tra:

Bash

docker ps
(N·∫øu th·∫•y tr·∫°ng th√°i Up l√† th√†nh c√¥ng).

(T√πy ch·ªçn) Truy c·∫≠p d√≤ng l·ªánh CQLSH:

Bash

docker exec -it cass-node cqlsh
G√µ exit ƒë·ªÉ tho√°t.

4. Thi·∫øt l·∫≠p M√¥i tr∆∞·ªùng Python
S·ª≠ d·ª•ng venv ƒë·ªÉ qu·∫£n l√Ω th∆∞ vi·ªán, tr√°nh xung ƒë·ªôt v·ªõi h·ªá th·ªëng.

B∆∞·ªõc 4.1: T·∫°o Virtual Environment
M·ªü PowerShell t·∫°i th∆∞ m·ª•c d·ª± √°n c·ªßa b·∫°n (V√≠ d·ª•: C:\Users\acer\MyProject):

PowerShell

# Ki·ªÉm tra phi√™n b·∫£n Python 3.10
py -3.10 --version

# T·∫°o m√¥i tr∆∞·ªùng ·∫£o t√™n l√† 'cassandra_env'
py -3.10 -m venv cassandra_env
B∆∞·ªõc 4.2: K√≠ch ho·∫°t m√¥i tr∆∞·ªùng
PowerShell

# Windows PowerShell
cassandra_env\Scripts\activate
Sau khi ch·∫°y, b·∫°n s·∫Ω th·∫•y (cassandra_env) ·ªü ƒë·∫ßu d√≤ng l·ªánh.

B∆∞·ªõc 4.3: C√†i ƒë·∫∑t th∆∞ vi·ªán
Copy v√† ch·∫°y l·ªánh sau ƒë·ªÉ c√†i ƒë·∫∑t to√†n b·ªô th∆∞ vi·ªán c·∫ßn thi·∫øt:

PowerShell

pip install pyspark cassandra-driver pandas matplotlib seaborn numpy
5. D·ªØ li·ªáu d·ª± √°n
Dataset

GitLab: The Attentive Cursor Dataset

Ch·∫°y th·ª≠ Code
Trong file Python (src/analysis.py) t·ª± t·∫°o m·ªõi, ƒëo·∫°n code ƒë·∫ßu ti√™n c·∫ßn c√≥ ƒë·ªÉ ki·ªÉm tra k·∫øt n·ªëi:

Python

import os
from pyspark.sql import SparkSession

# Test Spark
spark = SparkSession.builder \
    .appName("TestSetup") \
    .master("local[*]") \
    .getOrCreate()

print("Spark Version:", spark.version)
print("Environment Setup Successful!")
