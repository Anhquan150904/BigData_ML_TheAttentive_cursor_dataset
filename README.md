ğŸ“˜ HÆ°á»›ng Dáº«n Thiáº¿t Láº­p MÃ´i TrÆ°á»ng PhÃ¢n TÃ­ch Dá»¯ Liá»‡u (Spark & Cassandra)
TÃ i liá»‡u nÃ y hÆ°á»›ng dáº«n chi tiáº¿t cÃ¡ch cÃ i Ä‘áº·t mÃ´i trÆ°á»ng Ä‘á»ƒ cháº¡y dá»± Ã¡n phÃ¢n tÃ­ch hÃ nh vi ngÆ°á»i dÃ¹ng (Attentive Cursor Dataset) sá»­ dá»¥ng PySpark, Cassandra (Docker) vÃ  Python 3.10 trÃªn Windows.

ğŸ“‹ Má»¥c lá»¥c
YÃªu cáº§u há»‡ thá»‘ng & Táº£i pháº§n má»m

CÃ i Ä‘áº·t & Cáº¥u hÃ¬nh Biáº¿n mÃ´i trÆ°á»ng (Quan trá»ng)

CÃ i Ä‘áº·t Database Cassandra (Docker)

Thiáº¿t láº­p MÃ´i trÆ°á»ng Python

Dá»¯ liá»‡u dá»± Ã¡n

1. YÃªu cáº§u há»‡ thá»‘ng & Táº£i pháº§n má»m
Vui lÃ²ng táº£i xuá»‘ng cÃ¡c thÃ nh pháº§n sau (chÆ°a cáº§n cÃ i Ä‘áº·t ngay, chá»‰ cáº§n táº£i vá»):

A. Java Development Kit (JDK)
Spark yÃªu cáº§u Java Ä‘á»ƒ cháº¡y.

PhiÃªn báº£n: Java 11 (LTS)

Link táº£i: Adoptium Temurin OpenJDK 11

LÆ°u Ã½: Chá»n file cÃ i Ä‘áº·t .msi cho Windows (x64).

B. Apache Spark
PhiÃªn báº£n: 3.5.1 (Pre-built for Hadoop 3.3)

Link táº£i: Huawei Cloud Repo - spark-3.5.1-bin-hadoop3.tgz

LÆ°u Ã½: File nÃ y táº£i vá» cáº§n giáº£i nÃ©n, khÃ´ng cáº§n cháº¡y cÃ i Ä‘áº·t.

C. Hadoop Winutils (Cho Windows)
Windows cáº§n file nÃ y Ä‘á»ƒ giáº£ láº­p mÃ´i trÆ°á»ng Hadoop.

PhiÃªn báº£n: Hadoop 3.3.6

Link táº£i: Winutils GitHub (winutils.exe)

Cáº§n táº£i thÃªm: hadoop.dll (cÃ¹ng thÆ° má»¥c trong link trÃªn náº¿u cÃ³, hoáº·c tÃ¬m trong repo Ä‘Ã³).

D. Python
PhiÃªn báº£n: 3.10.x

Link táº£i: Python 3.10.11 Download

2. CÃ i Ä‘áº·t & Cáº¥u hÃ¬nh Biáº¿n mÃ´i trÆ°á»ng (Quan trá»ng)
ÄÃ¢y lÃ  bÆ°á»›c quan trá»ng nháº¥t, náº¿u lÃ m sai Spark sáº½ khÃ´ng cháº¡y.

BÆ°á»›c 2.1: CÃ i Ä‘áº·t Java
Cháº¡y file cÃ i Ä‘áº·t JDK 11 Ä‘Ã£ táº£i.

Ghi nhá»› Ä‘Æ°á»ng dáº«n cÃ i Ä‘áº·t (VÃ­ dá»¥: C:\Program Files\Eclipse Adoptium\jdk-11.0.18.10-hotspot).

BÆ°á»›c 2.2: Giáº£i nÃ©n Spark
Giáº£i nÃ©n file spark-3.5.1-bin-hadoop3.tgz (dÃ¹ng WinRAR hoáº·c 7-Zip).

Di chuyá»ƒn thÆ° má»¥c Ä‘Ã£ giáº£i nÃ©n ra á»• Ä‘Ä©a gá»‘c Ä‘á»ƒ tÃªn ngáº¯n gá»n.

VÃ­ dá»¥: D:\Spark\spark-3.5.1-bin-hadoop3

BÆ°á»›c 2.3: CÃ i Ä‘áº·t Winutils (Hadoop Home)
Táº¡o thÆ° má»¥c: D:\Hadoop

Trong thÆ° má»¥c Ä‘Ã³, táº¡o tiáº¿p thÆ° má»¥c bin -> D:\Hadoop\bin

Copy file winutils.exe (vÃ  hadoop.dll náº¿u cÃ³) vÃ o thÆ° má»¥c D:\Hadoop\bin.

BÆ°á»›c 2.4: Cáº¥u hÃ¬nh Environment Variables
Má»Ÿ Edit the system environment variables trÃªn Windows -> Báº¥m Environment Variables.

Táº¡o cÃ¡c biáº¿n má»›i (System Variables - Pháº§n bÃªn dÆ°á»›i):

JAVA_HOME: C:\Program Files\Eclipse Adoptium\jdk-11... (Ä‘Æ°á»ng dáº«n cÃ i Java).

HADOOP_HOME: D:\Hadoop (ThÆ° má»¥c chá»©a folder bin).

SPARK_HOME: D:\Spark\spark-3.5.1-bin-hadoop3

Cáº­p nháº­t biáº¿n PATH:

TÃ¬m biáº¿n Path trong System Variables -> Báº¥m Edit.

ThÃªm má»›i (New) cÃ¡c dÃ²ng sau:

%JAVA_HOME%\bin

%HADOOP_HOME%\bin

%SPARK_HOME%\bin

3. CÃ i Ä‘áº·t Database Cassandra (Docker)
Sá»­ dá»¥ng Docker Ä‘á»ƒ cháº¡y Cassandra server nhanh chÃ³ng.

Má»Ÿ CMD hoáº·c PowerShell.

Táº£i áº£nh (Image):

Bash

docker pull cassandra:4.1
Cháº¡y Container:

Bash

docker run --name cass-node -d -p 9042:9042 cassandra:4.1
Kiá»ƒm tra:

Bash

docker ps
(Náº¿u tháº¥y tráº¡ng thÃ¡i Up lÃ  thÃ nh cÃ´ng).

(TÃ¹y chá»n) Truy cáº­p dÃ²ng lá»‡nh CQLSH:

Bash

docker exec -it cass-node cqlsh
GÃµ exit Ä‘á»ƒ thoÃ¡t.

4. Thiáº¿t láº­p MÃ´i trÆ°á»ng Python
Sá»­ dá»¥ng venv Ä‘á»ƒ quáº£n lÃ½ thÆ° viá»‡n, trÃ¡nh xung Ä‘á»™t vá»›i há»‡ thá»‘ng.

BÆ°á»›c 4.1: Táº¡o Virtual Environment
Má»Ÿ PowerShell táº¡i thÆ° má»¥c dá»± Ã¡n cá»§a báº¡n (VÃ­ dá»¥: C:\Users\acer\MyProject):

PowerShell

# Kiá»ƒm tra phiÃªn báº£n Python 3.10
py -3.10 --version

# Táº¡o mÃ´i trÆ°á»ng áº£o tÃªn lÃ  'cassandra_env'
py -3.10 -m venv cassandra_env
BÆ°á»›c 4.2: KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
PowerShell

# Windows PowerShell
cassandra_env\Scripts\activate
Sau khi cháº¡y, báº¡n sáº½ tháº¥y (cassandra_env) á»Ÿ Ä‘áº§u dÃ²ng lá»‡nh.

BÆ°á»›c 4.3: CÃ i Ä‘áº·t thÆ° viá»‡n
Copy vÃ  cháº¡y lá»‡nh sau Ä‘á»ƒ cÃ i Ä‘áº·t toÃ n bá»™ thÆ° viá»‡n cáº§n thiáº¿t:

PowerShell

pip install pyspark cassandra-driver pandas matplotlib seaborn numpy
5. Dá»¯ liá»‡u dá»± Ã¡n
Dataset
Táº£i bá»™ dá»¯ liá»‡u The Attentive Cursor Dataset táº¡i link sau:

GitLab: The Attentive Cursor Dataset

Cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n (Gá»£i Ã½)
Sau khi hoÃ n táº¥t, thÆ° má»¥c dá»± Ã¡n cá»§a báº¡n nÃªn trÃ´ng nhÆ° sau Ä‘á»ƒ dá»… quáº£n lÃ½:

Plaintext

MyProject/
â”œâ”€â”€ cassandra_env/          # MÃ´i trÆ°á»ng áº£o Python
â”œâ”€â”€ data/                   # Chá»©a dá»¯ liá»‡u táº£i tá»« GitLab
â”‚   â””â”€â”€ cursor_data.csv
â”œâ”€â”€ src/                    # Chá»©a code Python
â”‚   â””â”€â”€ analysis.py
â””â”€â”€ README.md
Cháº¡y thá»­ Code
Trong file Python (src/analysis.py), Ä‘oáº¡n code Ä‘áº§u tiÃªn cáº§n cÃ³ Ä‘á»ƒ kiá»ƒm tra káº¿t ná»‘i:

Python

import os
from pyspark.sql import SparkSession

# Test Spark
spark = SparkSession.builder \
    .appName("TestSetup") \
    .master("local[*]") \
    .getOrCreate()

print("Spark Version:", spark.version)
print("Environment Setup Successful!")